{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekczNcQxUpzT"
   },
   "source": [
    "# Your Uni : Fill Here. (Also change Uni in the title of your notebook)\n",
    "# Your Full name : Fill Here\n",
    "# Link to your Public Github repository with Final report  : Fill here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Due Date: 03/07/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXxGTgJz152A"
   },
   "source": [
    "# World Happiness Classification Competition\n",
    "Goals :\n",
    "- Understand how the models function\n",
    "- Understand what the parameters control\n",
    "- Learn from the model experimentation process\n",
    "- Make a good looking notebook report\n",
    "- Upload as a personal project on Github\n",
    "\n",
    "**Overall Steps:**\n",
    "1. Load datasets and merge them.\n",
    "2. Preprocess data using Sklearn Column Transformer/ Write and Save Preprocessor function\n",
    "3. Fit model on preprocessed data and save preprocessor function and model\n",
    "4. Generate predictions from X_test data and submit predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gSrVJwp3E9H"
   },
   "source": [
    "## 0. Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the World Happiness 2023 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_expectancy</th>\n",
       "      <th>freedom_to_make_life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>perceptions_of_corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.804</td>\n",
       "      <td>1.888</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.586</td>\n",
       "      <td>1.949</td>\n",
       "      <td>1.548</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.530</td>\n",
       "      <td>1.926</td>\n",
       "      <td>1.620</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>7.473</td>\n",
       "      <td>1.833</td>\n",
       "      <td>1.521</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.403</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.488</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Congo (Kinshasa)</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>3.207</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>3.204</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>3.138</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Lebanon</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>2.392</td>\n",
       "      <td>1.417</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>1.859</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              country                        region  happiness_score  \\\n",
       "0             Finland                Western Europe            7.804   \n",
       "1             Denmark                Western Europe            7.586   \n",
       "2             Iceland                Western Europe            7.530   \n",
       "3              Israel  Middle East and North Africa            7.473   \n",
       "4         Netherlands                Western Europe            7.403   \n",
       "..                ...                           ...              ...   \n",
       "132  Congo (Kinshasa)            Sub-Saharan Africa            3.207   \n",
       "133          Zimbabwe            Sub-Saharan Africa            3.204   \n",
       "134      Sierra Leone            Sub-Saharan Africa            3.138   \n",
       "135           Lebanon  Middle East and North Africa            2.392   \n",
       "136       Afghanistan                    South Asia            1.859   \n",
       "\n",
       "     gdp_per_capita  social_support  healthy_life_expectancy  \\\n",
       "0             1.888           1.585                    0.535   \n",
       "1             1.949           1.548                    0.537   \n",
       "2             1.926           1.620                    0.559   \n",
       "3             1.833           1.521                    0.577   \n",
       "4             1.942           1.488                    0.545   \n",
       "..              ...             ...                      ...   \n",
       "132           0.531           0.784                    0.105   \n",
       "133           0.758           0.881                    0.069   \n",
       "134           0.670           0.540                    0.092   \n",
       "135           1.417           0.476                    0.398   \n",
       "136           0.645           0.000                    0.087   \n",
       "\n",
       "     freedom_to_make_life_choices  generosity  perceptions_of_corruption  \n",
       "0                           0.772       0.126                      0.535  \n",
       "1                           0.734       0.208                      0.525  \n",
       "2                           0.738       0.250                      0.187  \n",
       "3                           0.569       0.124                      0.158  \n",
       "4                           0.672       0.251                      0.394  \n",
       "..                            ...         ...                        ...  \n",
       "132                         0.375       0.183                      0.068  \n",
       "133                         0.363       0.112                      0.117  \n",
       "134                         0.371       0.193                      0.051  \n",
       "135                         0.123       0.061                      0.027  \n",
       "136                         0.000       0.093                      0.059  \n",
       "\n",
       "[137 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "whr_df = pd.read_csv('data/WHR_2023.csv')\n",
    "\n",
    "# Inspect the first few rows to understand the structure\n",
    "whr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the regression target ('happiness_score') into classification labels\n",
    "# We'll use quartiles to create 4 happiness categories: Very Low, Low, High, Very High\n",
    "\n",
    "# Define quartiles\n",
    "whr_df['happiness_category'] = pd.qcut(whr_df['happiness_score'], \n",
    "                                       q=5, \n",
    "                                       labels=['Very Low', 'Low','Average', 'High', 'Very High'])\n",
    "\n",
    "# Select features and target\n",
    "X = whr_df.drop(columns=['happiness_score', 'happiness_category'])\n",
    "y = whr_df['happiness_category']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Convert y_train and y_test to numerical labels\n",
    "y_train_labels = y_train.astype('category').cat.codes\n",
    "# y_test_labels = ## Complete in a similar manner as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvTXc7QOl5s7"
   },
   "source": [
    "Write in the next cell what the y_train.astype('category').cat.codes line does. What is the difference between y_train_labels and y_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsFZm1z0l0EC"
   },
   "outputs": [],
   "source": [
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbevDQ9_8-pt"
   },
   "source": [
    "<h3> Add new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFBU6SBm896W"
   },
   "outputs": [],
   "source": [
    "# Truncated and cleaned up region data to merge\n",
    "countrydata=pd.read_csv(\"data/newcountryvars.csv\")\n",
    "\n",
    "countrydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iMJhqME9Lmq"
   },
   "outputs": [],
   "source": [
    "# Merge in new data to X_train and X_test by taking \"country\" from first table and \"country_name\" from 2nd table.\n",
    "# Also check which countries are common in both the datasets, and which type of merge will you perform for the best results.\n",
    "# Hint: Look on the 'how' parameter of megre function of pandas.\n",
    "\n",
    "X_train = ## Complete code\n",
    "X_test = ## Complete code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAcRWzym-4iT"
   },
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MV_a5QaydpZ"
   },
   "source": [
    "## 1.  EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM5kFt5zC4yn"
   },
   "outputs": [],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBngMQdmykLZ"
   },
   "source": [
    "Describe what you see above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Phkm6BKCyjuF"
   },
   "outputs": [],
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmlG3-8Tys3-"
   },
   "source": [
    "Find out the number and percentage of missing values in the table per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejFHu-84y2Nr"
   },
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7Q3_DMwy4sX"
   },
   "source": [
    "Plot the frequency distribution / histogram of some of the numerical features that you think are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neosQxQRzKfq"
   },
   "outputs": [],
   "source": [
    "# Your plotting code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0MxV_o9zNCE"
   },
   "source": [
    "Plot the categorical variables and their distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17wHJ4hYzRkv"
   },
   "outputs": [],
   "source": [
    "# Your plotting code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature correlation analysis to identify relationships between variables. Use Pearson, Spearman, or Kendall correlation coefficients to analyze feature dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oi3lA3QElvZh"
   },
   "source": [
    "Explore relationships between variables (bivariate, etc), correlation tables, and how they associate with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91OgPpv8mQ3T"
   },
   "outputs": [],
   "source": [
    "# Your plotting code(s) here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, detect outliers using box plots, Z-score analysis, or the IQR method to identify potential data anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "878CQ8e9zTf_"
   },
   "source": [
    "Write what you observed and your General comments on what should be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_C7nCaYzZ_O"
   },
   "outputs": [],
   "source": [
    "# Your comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply log transformations to normalize skewed data and improve model stability (If any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create at least one interaction feature to capture relationship between existing variables, enhancing predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzPoXPj3V7u"
   },
   "source": [
    "## 3.   Preprocess data using Sklearn Column Transformer/ Write and Save Preprocessor function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16QV9Y9TC3B3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Create the preprocessing pipelines for both numeric and categorical data.\n",
    "\n",
    "numeric_features = ## Drop all the non-numerical features from X_train\n",
    "numeric_features=numeric_features.columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)), ## Is this good enough?\n",
    "    ('scaler', StandardScaler())]) # You will need to describe why this is being done in the next cell\n",
    "\n",
    "categorical_features = ['region', 'sub-region']\n",
    "\n",
    "#Replacing missing values with Modal value and then one hot encoding.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer',  ## Fill here )),\n",
    "    ('onehot', OneHotEncoder(handle_unknown= ## Fill here  ))])\n",
    "\n",
    "# final preprocessor object set up with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#Fit your preprocessor object\n",
    "preprocess=preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-_wL1ZfnnRr"
   },
   "source": [
    "Describe step-by-step what we are doing above, and why? You are free to change how values are imputed. What change did you make if any, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_k1H1XvnlEg"
   },
   "outputs": [],
   "source": [
    "## Your answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_PaNOG0SUIk"
   },
   "outputs": [],
   "source": [
    "# Write function to transform data with preprocessor\n",
    "\n",
    "def preprocessor(data):\n",
    "    data.drop(['country', 'region'], axis=1)\n",
    "    preprocessed_data=preprocess.transform(data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihlVBhHQnxdU"
   },
   "source": [
    "What are the differences between the \"preprocessor\" object, the \"preprocess\" object, the \"preprocessor\" function,  and the \"preprocessed_data\" that is returned finally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgszpguCoBkB"
   },
   "outputs": [],
   "source": [
    "## Your Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1IPy9xvSWBp"
   },
   "outputs": [],
   "source": [
    "# check shape of X data after preprocessing it using our new function\n",
    "preprocessor(X_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X52kECL43b-O"
   },
   "source": [
    "## 4. Fit model on preprocessed data and save preprocessor function and model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCbBf8j9ClYl"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = ## Define a Random Forest Model here, fit it, and score it\n",
    "\n",
    "# Your cell should have a score between 0-1 as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHWkAzvX3m8O"
   },
   "source": [
    "## 5. Generate predictions from X_test data and compare it with true labels in Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Ql4wksyEUnP"
   },
   "outputs": [],
   "source": [
    "#-- Generate predicted values (Model 1)\n",
    "prediction_labels = model.predict(preprocessor(X_test))\n",
    "\n",
    "## Write code to show model performance by comparing prediction_labels with true labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLg12oeqeP12",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 6. Repeat the process with different parameters to improve the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYG5FywVeP17"
   },
   "outputs": [],
   "source": [
    "# Train model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_2 = ## Make a new model with changed parameters to improve the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYMEPL2UrWn8"
   },
   "source": [
    " What changes did you make, what do the parameters you changed control, and why does it improve performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaGdMOIcrmX2"
   },
   "outputs": [],
   "source": [
    "## Your answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nszPPrfwPlUk"
   },
   "outputs": [],
   "source": [
    "#Evaluate Model 2:\n",
    "\n",
    "#-- Generate predicted y values (Model 2)\n",
    "prediction_labels = # Predict\n",
    "\n",
    "## Write code to show model performance by comparing prediction_labels with true labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhzJ7NGOtehX"
   },
   "source": [
    "Do you think it is worth making more changes to the parameters? Should we keep trying random values and see what works better? What is an alternative to doing this manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Sx3ivg1td_B"
   },
   "outputs": [],
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Go4SF37Ex_Z"
   },
   "outputs": [],
   "source": [
    "# Submit a third model using GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = # Use np.arange to create a sequence of numbers for each parameter's space you think should be searched\n",
    "\n",
    "gridmodel = # Read GridSearchCV docs and create an object with RandomForestClassifier as the model\n",
    "\n",
    "#use model methods to fit score and predict model:\n",
    "\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(gridmodel.best_score_))\n",
    "print(\"best parameters: {}\".format(gridmodel.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMidHABfHVN7"
   },
   "outputs": [],
   "source": [
    "#Submit Model 3:\n",
    "\n",
    "#-- Generate predicted values\n",
    "\n",
    "\n",
    "## Write code to show model performance by comparing prediction_labels with true labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tukB40NshcaB"
   },
   "outputs": [],
   "source": [
    "# Here are several classic ML architectures you can consider choosing from to experiment with next:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "model = ## Read documentations of imported models and fit them.\n",
    "\n",
    "#-- Generate predicted values\n",
    "prediction_labels = model.predict(preprocessor(X_test))\n",
    "\n",
    "## Write code to show model performance by comparing prediction_labels with true labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeZ16W4GuUW9"
   },
   "source": [
    "Describe what were the parameters you defined in GradientBoostingClassifier, and/or BaggingClassifier, and/or KNNs, and/or SVC? What worked and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJkWFWGPuGk2"
   },
   "outputs": [],
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e-V2vtMmrrp"
   },
   "source": [
    "## 7. Basic Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Me2pkDUsuEBH"
   },
   "outputs": [],
   "source": [
    "# Now experiment with deep learning models:\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "feature_count=#count features in input data\n",
    "\n",
    "keras_model = ## Define a Neural Network Model with 5 layers 128->64->64->32->(?)\n",
    "\n",
    "\n",
    "#Use Softmax activation in last layer. How many neurons should there be in the last layer?\n",
    "\n",
    "\n",
    "\n",
    "# Compile model\n",
    "keras_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "keras_model.fit(preprocessor(X_train), y_train, ## Note that keras models require a one-hot-encoded y_train object\n",
    "               batch_size = 20,\n",
    "               epochs = 300, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ioCyMzn004c"
   },
   "source": [
    "Which activations did you use in the middle layers? Why was softmax used in the last layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIDjsg1C07Iq"
   },
   "outputs": [],
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJjQq2Uzu3IW"
   },
   "source": [
    "Was it a good idea to train for 300 epochs? Should you train a bit more? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfyiD8SKvF-C"
   },
   "outputs": [],
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHwaKILrvID4"
   },
   "source": [
    "Why is loss='categorical_crossentropy' and optimizer='sgd'? Would you want to change something? Why / Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmpDqteVv8wa"
   },
   "outputs": [],
   "source": [
    "## Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT8-NUAaopVb"
   },
   "source": [
    "Can you try getting the model's training history out and plotting the curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtmlgVsAoyU7"
   },
   "outputs": [],
   "source": [
    "## Your code to plot training and validation curves in a single plot (Make changes in the model cell to be able to do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_uMRKnGu-wC"
   },
   "outputs": [],
   "source": [
    "#-- Generate predicted y values\n",
    "\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index= # Predict\n",
    "\n",
    "# extract correct prediction labels\n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "## Write code to show model performance by comparing prediction_labels with true labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement regularization techniques such as Dropout and Batch Normalization to improve model generalization and observe change in performance. <br>\n",
    "Note: Observe the training and testing loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comments about the change in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different activation functions (ReLU, LeakyReLU, Tanh, Sigmoid) to observe their impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Explainability - SHAP Feature Importance\n",
    "\n",
    "To better understand our model's predictions, we will use **SHAP (SHapley Additive exPlanations)** to analyze feature importance.  \n",
    "\n",
    "### ðŸ”¹ How SHAP Works?\n",
    "- SHAP assigns each feature a **contribution score** for every prediction.\n",
    "- Uses **Shapley values** (from game theory) to fairly distribute importance across features.\n",
    "\n",
    "We will now apply SHAP to visualize and interpret our modelâ€™s feature contributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "# Define an explainer that will help us interpret the model's decisions\n",
    "# (Hint: Use shap.Explainer with the trained model and X_test data)\n",
    "\n",
    "explainer = ## Initialize SHAP explainer using the trained model\n",
    "\n",
    "# Compute SHAP values for X_test\n",
    "# This step generates Shapley values, which explain how each feature contributes to predictions\n",
    "shap_values = ## Apply the explainer to X_test\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "# This plot will show which features have the most impact on predictions\n",
    "shap.summary_plot(## Pass the required parameters to create a summary plot)\n",
    "\n",
    "# Your cell should output a SHAP summary plot showing the most important features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnsyzAcHwOiI"
   },
   "outputs": [],
   "source": [
    "## You are encouraged to try more experimentation and any other models by adding more code cells to this notebook:\n",
    "\n",
    "## You can also try to import any new dataset pertaining to countries, merge it, and see if it helps the predictions.\n",
    "## If it does not, try to explain why it wasn't helpful by exploring variable relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u79b6VFqeP19",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Deep learning models are often considered 'black boxes' due to their complexity. Explore methods such as SHAP (SHapley Additive exPlanations) to explain your model's predictions. After applying one of these methods, do you feel it provides a clear and sufficient explanation of how your model makes decisions? How easy or difficult is it to justify your model's predictions using these techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeJ9bKQNeP19"
   },
   "outputs": [],
   "source": [
    "## Your Code and Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAy-p3odm0zv"
   },
   "source": [
    "## 9. Submission of final report and clean code to github\n",
    "\n",
    "[This is a final project you display on your GitHub to the World]\n",
    "\n",
    "**Instructions**\n",
    "- Make a new notebook, visualize any plots you found relevant\n",
    "- Reproduce the code you used for the best models and display results\n",
    "- Write what insights you found useful and what behaviours were observed\n",
    "- Make it in a style of a clean, succint report (within the .ipynb)\n",
    "- Upload this final report notebook to a new repository in your personal github account\n",
    "- Remember to paste the link of your final repo at the top of this notebook where asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3KjLkz5plvF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
